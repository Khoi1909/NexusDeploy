# NOTE for CURSOR: THIS env example will always be the same as env file. DO NOT edit both env files

#Github auth
GITHUB_CLIENT_ID=your-github-oauth-clientID
GITHUB_CLIENT_SECRET=your-github-oauth-secret

# Ollama AI Service (Local Docker)
# Ollama runs as a Docker service in nexus-network
# Model: DeepSeek Coder 6.7B (q4_0) - ~3.83 GB, optimized for code analysis
LLM_API_URL=http://ollama:11435/api/generate
LLM_MODEL=deepseek-coder:6.7b-q4_0
# Note: No LLM_API_KEY needed for local Ollama
# First time setup: docker exec nexus_ollama ollama pull deepseek-coder:6.7b-q4_0
FRONTEND_URL=http://localhost:3001
NEXT_PUBLIC_API_URL=
# Traefik Domain Configuration
TRAEFIK_DOMAIN_SUFFIX=mydomain.com

# Cloudflare DNS API for Let's Encrypt wildcard certificates
CLOUDFLARE_EMAIL=your-email@example.com
CLOUDFLARE_DNS_API_TOKEN=your-cloudflare-api-token
